\chapter{Eine Anwendung für mobiles Maschinelles Lernen}
\label{chap:application}
Jetzt, wo ein Netz trainiert, bewertet,
in das TensorFlow Lite Format gewandelt und verglichen wurde,
heißt es das ausgewählte Modell in der Praxis einzusetzen.
Ein neuronales Netz allein, welches hervorragende Prognosen
macht, reicht jedoch nicht, um ein nützliches Produkt zu entwickeln:
Das Modell muss in einer Anwendung integriert werden, sodass
der Benutzer oder andere Teile des Systems
mit den Modellergebnissen interagieren können.
Der Entwurf einer solchen Anwendung ist die
Fokussierung dieses Kapitels.

\section{Die allgemeine Architektur auslegen}
Wie in \autoref{sec:problem-description} beschrieben wurde, ist es
typischerweise eine gute Idee, das Modell in einen Service zu verpacken.
Andere Teile der Anwendung können so jederzeit auf die Vorhersagen
des Netzes zugreifen. Dies ermöglicht es, neue Versionen
einzuspielen, ohne die Hauptanwendung zu unterbrechen.
Zusätzlich kann die Entwicklung flexibler gestaltet werden,
da es keine Einschränkung auf bestimmte Technologien
und Programmiersprachen gibt. Es kann so jederzeit das
beste Werkzeug für das zu lösende Problem ausgewählt werden.
Der Dienst, welcher das Modell ausführt, könnte in Python oder \cpp{}
geschrieben sein, und obwohl es möglich ist, Benutzeroberflächen 
in Python zu entwerfen, ist \cpp{} wahrscheinlich nicht das
richtige Hilfsmittel für diese Aufgabe.
Besser wäre es womöglich eine Sprache für das Web auszuwählen, 
wie zum Beispiel JavaScript.
\autoref{fig:app-architecture} zeigt die Architektur der Anwendung.
\begin{figure}[h!]
  \centering
  \includegraphics[width=\wLG]{app/app-architecture.pdf}
  \caption{Die Architektur der Anwendung: Ein Modell, das als Dienst
  bereitgestellt wird und verschiedene Services, die mit diesem kommunizieren}
  \label{fig:app-architecture}
\end{figure}

\noindent
Jedes Objekt mit einer Pfeilspitze spiegelt einen Service wieder, insgesamt sind
es sieben Stück. Ein Service ist eine unabhängige, wenn möglich kleine und
unkomplizierte Anwendung, welche nicht mehr als eine Aufgabe übernimmt.
Um die Verwaltung dieser Services zu erleichtern, wird Docker eingesetzt.
Jeder Dienst kann so isoliert in seinem eigenen Docker-Container ausgeführt
und über Docker-Netzwerke verbunden werden.\\[8pt]
Docker ist eine Freie Software, welche auf Linux, Windows und macOS
läuft. Sie erstellt und verwaltet Container
und kann diese sogar orchestrieren.
Docker, Inc., gegründet in 2008 (ursprünglich \textit{dotCloud} und später unter
dem Spitznamen \enquote{Docker}), ist das Unternehmen,
welche die Software entwickelt hat \parencite{onlide:docker-inc}.
Das Wort \enquote{Docker} kommt aus dem Englischen
und bedeutet \textit{\underline{dock} work\underline{er}} --
eine Person im Hafen die Schiffe be- und entlädt.
Es ermöglicht das einfache Teilen von Software
durch Docker-Images (einschließlich aller Abhängigkeiten
und in der Regel geeigneter Standardkonfiguration) und kann
diese mithilfe der Docker-Engine ausführen.
Wird ein Image ausgeführt, erstellt die Engine einen Docker-Container,
mit dem die Anwendung gut isoliert vom restlichen System gestartet wird.
Es ist ähnlich wie eine virtuelle Maschine,
nur viel schneller und schlanker, 
da der Container direkt auf dem Kernel des Hostbetriebssystems aufsetzt
\parencite[11-14]{book:docker-dd} \parencite[672]{book:hands-on-ml}.\\[8pt]
Docker eignet sich somit gut, um eine Anwendung mit der in dieser Arbeit beschriebenen
Zielsetzung zu entwickeln, die jeder herunterladen und mit ein paar Befehlen
auf dem eigenen System ausführen kann. Der Quelltext zur Anwendung
sowie die bisherigen Programmausschnitte
befinden such auf dem GitHub-Profil des Autors.
Die Docker-Images der in \autoref{fig:app-architecture} zu sehenden
Services sind über Docker Hub verfügbar.
Docker Hub ist eine Plattform zum Teilen von Docker-Images und das als Standard
eingestellte Image-Register einer neuen Installation der Docker Software.
Ein Image-Register enthält ein oder mehrere Image-Repositorys
und diese enthalten wiederum ein oder mehrere Images.
Die folgenden Punkte fassen die wichtigsten Links zusammen:
\begin{itemize}
  \item Der Quelltext zur Anwendung auf GibHub
        (\url{https://github.com/JensDll/coral-ml}).
  \item Die bisherigen Programme und Ausschnitte zum Erstellen der Abbildungen
        (\url{https://github.com/JensDll/bachelorarbeit-notebooks}).
  \item Die Docker-Images der Services auf Docker Hub
        (\href{https://hub.docker.com/repository/docker/jensdll/coral-ml}
        {https://hub.docker.com/reposito\allowbreak ry/docker/jensdll/coral-ml}).
\end{itemize}

\section{Herunterladen der Dienste}
Um ein Image von Docker Hub herunterzuladen, wird
der \consoleinline{docker pull} Befehl verwendet.
Für offizielle Image-Repositorys nimmt dieser Befehl die folgende Form an:
\begin{consolecode}
$ docker pull <repository>:<tag>
\end{consolecode}
Es wird das Repository zusammen mit dem gewünschten Image
in der Form eines Tags angegeben.
Offizielle Repositorys sind ein Prinzip von Docker Hub.
Hier befinden sich von Docker Inc. ausgewählte
Images, die speziell geprüft, getestet,
gut dokumentiert und sicher sein sollten.
Die meisten populären und etablierten Anwendungen
und Betriebssysteme haben ihre eigenen
offiziellen Repositorys.
Diese sind Teil der obersten Ebene des Docker Hub Namensraums.
Das Abrufen von Images aus inoffiziellen Repositorys
ist im Wesentlichen dasselbe, hierfür
muss dem Repository-Namen
lediglich den Docker Hub Benutzernamen oder die Organisation
vorangestellt werden.
Der folgende Befehl lädt zum Beispiel das neuste
Benutzeroberflächen-Image aus dem \consoleinline{coral-ml}
Repository herunter, das der Person gehört, deren Docker Hub Benutzername
\consoleinline{jensdll} ist:
\begin{consolecode}
$ docker pull jensdll/coral-ml:vue-app_latest
513c6babab2b: Pull complete
e0fc2ec040ad: Pull complete
b80eb69b3b2a: Pull complete
6b9432260a23: Pull complete
3e07e4cdac0e: Pull complete
e0984574aa06: Pull complete
7504b347e849: Pull complete
d8102b350cfa: Pull complete
a1e035743dcc: Pull complete
Digest: sha256:dc255cc3b2...14260180b2
Status: Downloaded newer image for jensdll/coral-ml:vue-app_latest
docker.io/jensdll/coral-ml:vue-app_latest
\end{consolecode}
Hier befinden sich alle Dienste der Anwendung.
Der Befehl \consoleinline{docker images} gibt Auskunft über die zur Zeit auf dem Host
verfügbaren Images, hier ist die neu geladene Anwendung nun zu sehen:
\begin{consolecode}
$ docker images
REPOSITORY         TAG              IMAGE ID       CREATED        SIZE
jensdll/coral-ml   vue-app_latest   3328de4e34a8   34 hours ago   126MB
\end{consolecode}
Derselbe Befehl kann auch für die restlichen Services ausgeführt werden:
\begin{consolecode}
$ docker pull jensdll/coral-ml:mariadb_latest
$ docker pull jensdll/coral-ml:record-api_latest
$ docker pull jensdll/coral-ml:node-api_latest
$ docker pull jensdll/coral-ml:node-video_latest
$ docker pull jensdll/coral-ml:proxy_latest
$ docker pull jensdll/coral-ml:coral-app_latest
\end{consolecode}
Das Docker-Image der Modell API trägt den Namen \consoleinline{record-api},
da dort neben den Modelldateien auch andere Informationen gespeichert werden,
wie zum Beispiel die Bezeichnungen der Klassen
für Klassifizierungsaufgaben in Form von Text- oder CSV-Dateien.
Ein Ausschnitt einer solchen Datei könnte wie folgt aussehen:
\begin{consolecode}
$ # Klassifizierung von Insektenbildern
$ cat labels.txt
Coccinella septempunctata (Seven-spotted Ladybird)
Zanclognatha jacchusalis (Wavy-lined Zanclognatha Moth)
[...]
Thasus neocalifornicus (Giant Mesquite Bug)
Palpita quadristigmalis (Four-spotted Palpita)
\end{consolecode}
Der Download der restlichen Dienste sollte nun abgeschlossen sein.
Ein erneuter Blick auf die verfügbaren Images führt zu folgendem Ergebnis:
\begin{consolecode}
$ docker images
REPOSITORY         TAG                 IMAGE ID       CREATED             SIZE
jensdll/coral-ml   vue-app_latest      ca8f49bae427   About an hour ago   126MB
jensdll/coral-ml   record-api_latest   bfb1e0f29b8b   About an hour ago   216MB
jensdll/coral-ml   coral-app_latest    8c9e9d79a019   About an hour ago   1.51GB
jensdll/coral-ml   node-api_latest     747e9d9c033c   About an hour ago   194MB
jensdll/coral-ml   node-video_latest   f184084a9639   About an hour ago   172MB
jensdll/coral-ml   mariadb_latest      0a215d70439a   About an hour ago   743MB
jensdll/coral-ml   proxy_latest        2ee77b530075   About an hour ago   126MB
\end{consolecode}

\section{Starten und Verbinden der Dienste}
Jetzt wo alle nötigen Images heruntergeladen sind, können
sie verwendet werden um die Anwendung zu starten.
\autoref{fig:container-image-relation} zeigt
die allgemeine Beziehung zwischen Docker-Image und Container.
\begin{figure}[h!]
  \centering
    \includegraphics[width=\wMD]{app/container-image-relation.pdf}
    \caption{Die allgemeine Beziehung zwischen
    Docker-Image und Container \parencite[52]{book:docker-dd}}
    \label{fig:container-image-relation}
\end{figure}

\noindent
Die Befehle \consoleinline{docker run}, \consoleinline{docker service create}
und \consoleinline{docker create} zusammen mit
\consoleinline{docker start} werden verwendet,
um ein oder mehrere Container von einem Image zu starten.
Nachdem ein Container erstellt wurde,
ist dieser fest an das zugrunde liegende Image gebunden.
Das Image kann erst dann gelöscht werden,
wenn es keine Container mehr gibt, die dieses verwenden.
Der Versuch, ein Image mit noch verbundenen Containern zu entfernen, führe zu einem Fehler.
Die Docker-Images der Anwendung sind alle zusammen kompatibel mit der ARM64-Architektur
und können daher vollständig auf einem Gerät wie dem
Siemens SIMATIC IOT2050 ausgeführt werden.
Das Bereitstellen einer containerisierten Anwendung ist ein zweiteiliger Prozess:
\begin{enumerate}
  \item Erstelle ein Netzwerk über das die Container kommunizieren.
  \item Lege die Container an, starte und verbinde sie mit dem Netzwerk.
\end{enumerate}
Wird die Anwendung auf einem einzelnen Host ausgeführt, bietet sich
die einfachste Form der Docker-Netzwerke an: dem \textit{single-host bridge network}.
Der Name verrät bereits zwei Dinge \parencite[155]{book:docker-dd}:
\begin{description}[style=nextline]
  \item[Single-Host]
  Das Netz existiert auf einem einzigen Docker-Host und kann auch nur Container
  von diesem Host verbinden.
  \item[Bridge]
  Es handelt sich um eine Implementierung des 802.1d Bridge Standards (Layer-2-Switch).
\end{description}
Der folgende Befehl erstellt ein \textit{single-host bridge network} mit dem Namen
\consoleinline{appnet}:
\begin{consolecode}
$ docker network create --driver bridge appnet
\end{consolecode}
Dieses taucht nun in der Liste der Docker-Netze auf:
\begin{consolecode}
$ docker network ls
NETWORK ID     NAME      DRIVER    SCOPE
2a64863b85ac   appnet    bridge    local
de8bf5113652   bridge    bridge    local
[...]
\end{consolecode}
Zusätzlich wurde auf Linux eine neue \textit{Linux bridge} im Kernel angelegt.
Diese können mit dem \textit{bridge control} Befehl
aus dem \textit{bridge-utils} Paket beobachtet werden:
\begin{consolecode}
$ brctl show
bridge name       bridge id           STP enabled   interfaces
br-2a64863b85ac   8000.02421cd6ffff   no
docker0           8000.0242b48f93e6   no
\end{consolecode}
Die Ausgabe zeigt zwei Netzwerkbrücken. Die erste Zeile (\consoleinline{br-2a64863b85ac})
bezieht sich auf die neu angelegte Docker-Brücke \consoleinline{appnet}.
Die zweite Zeile (\consoleinline{docker0}) korrespondiert mit der
von Docker erstellten Standard-Brücke. Keine der beiden Brücken
haben verbundene Geräte (\consoleinline{interfaces} Spalte).
Es können nun Container erstellt werden:
Die folgenden Befehle starten zwei Container mit Basis auf dem
\textit{Alpine Linux} Docker-Image, welches nur rund \qty{5}{\mega\byte} groß ist,
verbinden sie mit der Brücke und führen das Kommando \consoleinline{sleep 1d} aus:
\begin{consolecode}
$ docker run -d --network appnet --name c1 alpine sleep 1d
$ docker run -d --network appnet --name c2 alpine sleep 1d
\end{consolecode}
Ein Blick in das \consoleinline{appnet} Netz offenbart zwei verbundene Container:
\begin{consolecode}
$ docker network inspect appnet
[...]
"Containers": {
  "341ee8dfafa...d0401892a7d": {
    "Name": "c1",
    "EndpointID": "ad3241d27a7...3ba94ca3225",
    "MacAddress": "02:42:ac:12:00:02",
    "IPv4Address": "172.18.0.2/16",
    "IPv6Address": ""
  },
  "8c574b9a71e...7fa033427e9": {
    "Name": "c2",
    "EndpointID": "0f2a5f0dcdd...8dd3d481861",
    "MacAddress": "02:42:ac:12:00:03",
    "IPv4Address": "172.18.0.3/16",
    "IPv6Address": ""
  }
}
[...]
\end{consolecode}
Auch das \consoleinline{brctl} Kommando zeigt nun zwei angeschlossene Interfaces:
\begin{consolecode}
$ brctl show
bridge name       bridge id           STP enabled   interfaces
br-2a64863b85ac   8000.02421cd6ffff   no            veth063da62
                                                    veth3c4e683
docker0           8000.0242b48f93e6   no
\end{consolecode}
Innerhalb einer der Container sollte es nun möglich sein, den jeweils
anderen Container per Name zu erreichen.
Dies funktioniert deshalb, da alle Container automatisch
beim eingebetteten Docker DNS Dienst registriert werden
und so die Namen aller Container
im selben Netzwerk auflösen können \parencite[160]{book:docker-dd}.
Die folgenden Befehle testen die Verbindung:
\begin{consolecode}
$ # Bringe eine Shell an Container c1 an
$ docker exec -it c1 sh
(c1) $ # Ein Ping zu Container c2 per Name gelingt
(c1) $ ping c2 -c 2
PING c2 (172.18.0.3): 56 data bytes
64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.582 ms
64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.279 ms
\end{consolecode}
Die Namensauflösung funktioniert, Docker konnte dem Containernamen automatisch
die richtige IP-Adresse zuordnen.
Dies wird die Grundlage sein, wenn es darum geht
die unterschiedlichen Teile der Anwendung zu verbinden.
Zuerst werden die noch laufenden Container angehalten und entfernt:
\begin{consolecode}
$ docker stop c1 c2
$ docker rm c1 c2
\end{consolecode}
Die Anwendungscontainer können nun erstellt werden
und die folgenden Punkte beschreiben die nötigen Befehle.
\paragraph{Benutzeroberfläche}\mbox{}
\begin{consolecode}
$ docker create --network appnet -p 8080:80 \
>   --name vue-app jensdll/coral-ml:vue-app_latest
\end{consolecode}
Bislang hieß es, dass Container auf
Netzwerkbrücken nur mit anderen Containern im selben Netz kommunizieren können.
Mit Port-Mapping kann diese Eigenschaft umgangen werden. Der Befehl
\consoleinline{-p 8080:80} weist der Docker Engine an, den
TCP-Port 8080 des Hosts an den TCP-Port 80 des Containers weiterzuleiten.
Die Benutzeroberfläche kann so von außerhalb über die IP-Adresse des Geräts
an Port 8080 abgerufen werden.
\paragraph{Datenbank}\mbox{}
\begin{consolecode}
$ docker create --network appnet \
>   -e MARIADB_ROOT_PASSWORD='Pwd12345!' \
>   --name mariadb jensdll/coral-ml:mariadb_latest
\end{consolecode}
Dieser Befehl erstellt die Datenbank. Über die Umgebungsvariable
\consoleinline{MARIADB_ROOT_PASSWORD} wird das Passwort des Root-Nutzers angeben,
welches für die spätere Verbindung der API verwendet wird.
\paragraph{Modell API}\mbox{}
\begin{consolecode}
$ docker create --network appnet \
>   -e ConnectionStrings:RecordDb=\
> 'Server=mariadb,3306;Database=RecordDb;User Id=root;Pwd=Pwd12345!;' \
>   --name record-api jensdll/coral-ml:record-api_latest
\end{consolecode}
Dieser Befehl erstellt den Container zur Datenbankkommunikation.
In der Verbindungszeichenfolge wird das zuvor verwendete Passwort eingetragen.
\paragraph{Proxy}\mbox{}
\begin{consolecode}
$ docker create --network appnet -p 80:80 \
>   --name proxy jensdll/coral-ml:proxy_latest
\end{consolecode}
Der Proxy-Server muss über das öffentliche Netz vom Verbraucher aus erreichbar sein,
weshalb ein Port-Mapping von Port 80 nach 80 angegeben wird.
\paragraph{Node API}\mbox{}
\begin{consolecode}
$ docker create --network appnet \
>   --name node-api jensdll/coral-ml:node-api_latest
$ docker create --network appnet  \
>   --name node-video jensdll/coral-ml:node-video_latest
\end{consolecode}
Diese beiden APIs sind sich sehr ähnlich und dienen nur
der internen Kommunikation. Es wird daher nur das Netzwerk und der Containername
angegeben.
\paragraph{Coral App}\mbox{}
\begin{consolecode}
$ docker create --network appnet \
>   --device /dev/video0 --device /dev/apex_0 \
>   --name coral-app jensdll/coral-ml:coral-app_latest
\end{consolecode}
Als letzter Befehl wird die Coral Anwendung erstellt.
Der Container benötigt Zugriff auf verschiedene Hardwarekomponenten,
dieser kann gesetzt werden durch die \consoleinline{--device} Option.
Die \consoleinline{/dev/video0} Anweisung ermöglicht das Lesen
einer Videoquelle (zum Beispiel einer angeschlossen Webcam)
und die \consoleinline{/dev/apex_0} Gerätedatei ist der
Google Coral Half-Mini PCIe Anschluss \eqref{fig:iot2050}.\\[12pt]
Als letzter Schritt müssen die Container nur noch gestartet werden,
die Startreihenfolge ist hierbei relevant:
\begin{consolecode}
$ docker start mariadb record-api node-api node-video vue-app proxy coral-app 
\end{consolecode}
Zum Beispiel muss der Proxy-Container nach den APIs aber noch vor der Coral-App
gestartet werden. Die Anwendung wird nun ausgeführt mit sieben Containern
verbunden über eine lokale Netzwerkbrücke. Ein Blick auf die laufenden
Container ergibt folgende gekürzte Ausgabe:
\begin{consolecode}
$ docker container ls
CONTAINER ID   COMMAND                   STATUS         PORTS                  NAMES
19098722b243   "python main.py"          Up 4 minutes                          coral-app
270ca2c11b2e   "dotnet RecordAPI.dll"    Up 4 minutes   80/tcp                 record-api
14b6ca1e7c7f   "node bundle.min.js"      Up 4 minutes   80/tcp, 8080/tcp       node-video
6fb6af012163   "node bundle.min.js"      Up 4 minutes   80/tcp                 node-api
c9c5901cbbb4   "/docker-entrypoint..."   Up 4 minutes   0.0.0.0:80->80/tcp     proxy
53926b215876   "docker-entrypoint..."    Up 4 minutes   3306/tcp               mariadb
1eb49121c3ff   "/docker-entrypoint..."   Up 4 minutes   0.0.0.0:8080->80/tcp   vue-app
\end{consolecode}
Die Datenbank benötigt eine kurze Zeit,
um ein Backup wiederherzustellen.
Es sollten solange keine Anfragen durchgeführt werden,
da der API-Container ansonsten abstürzen könnte.
10 bis 15 Sekunden Wartezeit sollten ausreichen, geht dennoch etwas schief,
kann der jeweilige Container mit
dem Befehl \consoleinline{docker restart} neu gestartet werden.
Die Benutzeroberfläche ist über die IP-Adresse des Geräts
auf Port 8080 erreichbar.
\autoref{fig:website-on-devices} zeigt verschiedene
Teile der Webseite und wie diese auf unterschiedlichen Endgeräten aussieht.
\newpage
\input{chapters/application/tikz/website-on-devices.tex}

\noindent
Neben dem in \autoref{fig:ui-classification-example} gezeigten
Ausschnitt der Webseite zur Bildklassifizierung zeigen die
oberen Bilder den Videostream und die Verwaltung der verfügbaren
Modelle. Zum Zeitpunkt des Verfassens dieser Arbeit werden
verschiedenen Klassifizierungsmodelle und Objekterkennung
mit Video unterstützt. Bei den zu sehenden Netzen
handelt es sich um vom Coral-Team zur Verfügung gestellten
Demomodellen. Eine Erweiterung der Anwendung
durch zusätzliche Netzarchitekturen sollte
jedoch mit moderatem Aufwand möglich sein.
Das Video wird vom Aufnahmegerät über die Schnittstelle
an beliebig viele Verbraucher übertragen.
Auf dem IOT2050 wird hierbei eine
Bildwiederholrate von 10 bis \qty{15}{FPS} erreicht.
In Anbetracht der CPU Auslastung, welche durch die anderen
parallel laufenden Container entsteht,
reicht dies für flüssiges Video.